# ğŸ“Š AI-Powered Research Analyst

**Production-ready CLI system** that transforms scattered research documents into structured, executive-ready analysis reports using RAG and LangGraph orchestration.

## ğŸ¯ Overview

Building an AI-powered research analyst that acts like a junior consultant or enterprise research associate. The system:

- **Ingests scattered sources** (PDFs, websites, internal docs)
- **Uses Retrieval-Augmented Generation (RAG)** for accurate context retrieval
- **Chains tasks with LangGraph** for structured, step-wise analysis
- **Delivers executive-ready briefings** with citations and critical insights

**Essentially:** "Upload research papers â†’ receive consulting-grade briefing reports."

## âœ… Current Status: Production Ready

- âœ… **Core RAG Pipeline** - ChromaDB vector store, embedding service, semantic search
- âœ… **Document Processing** - Multi-format support (PDF, DOCX, TXT, URLs)
- âœ… **LangGraph Workflow** - 5-node orchestration pipeline
- âœ… **Enhanced LLM Processing** - Professional response post-processing
- âœ… **CLI Interface** - Production command-line tool
- âœ… **Citation Tracking** - Page-level source attribution

## ğŸš€ Quick Start

### 1. Environment Setup
```bash
# Install dependencies
pip install -r requirements.txt

# Or create conda environment
conda env create -f environment.yml
conda activate research_analyst
```

### 2. Local LLM Setup (DeepSeek via Ollama)
```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Pull DeepSeek model
ollama pull deepseek-r1:1.5b
```

### 3. Run Analysis
```bash
# Basic analysis
python research_cli.py paper.pdf -q "What are the main findings?"

# Advanced analysis with custom outputs
python research_cli.py *.pdf -q "Compare methodologies" \
  --analytics system_report.json --report findings.md
```

### 4. Output Files
- **system_analytics.json** - Performance metrics, system diagnostics
- **research_report.md** - Professional analysis with citations

## ğŸ—ï¸ System Architecture

### Core Components
1. **Document Ingestion Engine** - Multi-format document processing
2. **RAG Pipeline** - Vector embeddings + semantic search  
3. **LangGraph Orchestrator** - Task chaining workflow
4. **Analysis Engine** - Summarization + critical review
5. **Executive Briefing Generator** - Structured output with citations

### Tech Stack
- **LangChain/LangGraph** - Workflow orchestration
- **ChromaDB** - Vector database
- **DeepSeek LLM** - Local LLM processing via Ollama
- **Sentence Transformers** - Embeddings
- **CLI Interface** - Production command-line tool

### LangGraph Workflow (5-Node Pipeline)
```
Input â†’ [INGESTION] â†’ [RETRIEVAL] â†’ [SUMMARIZATION] â†’ [REVIEW] â†’ [REPORT] â†’ Output
         â†“            â†“             â†“               â†“         â†“
    Process PDFs   Find Relevant   Extract Key    Critical  Generate
    Store in RAG   Chunks         Insights       Analysis  Final Report
```

## ğŸ“ Project Structure

```
research_analyst/
â”œâ”€â”€ research_cli.py             # Main CLI interface
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ research_analyst/       # Core system
â”‚   â”‚   â”œâ”€â”€ enhanced_research_analyst.py
â”‚   â”‚   â”œâ”€â”€ rag/               # RAG pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ rag_pipeline.py
â”‚   â”‚   â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”‚   â”‚   â””â”€â”€ retrieval.py
â”‚   â”‚   â”œâ”€â”€ workflow/          # LangGraph orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ workflow.py
â”‚   â”‚   â”‚   â”œâ”€â”€ nodes.py
â”‚   â”‚   â”‚   â””â”€â”€ agents.py
â”‚   â”‚   â”œâ”€â”€ output/            # Report generation
â”‚   â”‚   â”‚   â”œâ”€â”€ response_processor.py
â”‚   â”‚   â”‚   â””â”€â”€ markdown_formatter.py
â”‚   â”‚   â””â”€â”€ analysis/          # Advanced analysis
â”‚   â”‚       â”œâ”€â”€ fact_verifier.py
â”‚   â”‚       â””â”€â”€ contradiction_detector.py
â”‚   â”œâ”€â”€ core/                  # Document processing
â”‚   â”‚   â”œâ”€â”€ document_ingestion.py
â”‚   â”‚   â””â”€â”€ file_processors.py
â”‚   â””â”€â”€ config/                # Configuration
â”‚       â””â”€â”€ settings.py
â”œâ”€â”€ tests/                     # Test suite
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ environment.yml           # Conda environment
â”œâ”€â”€ CLAUDE.md                 # Project documentation
â””â”€â”€ README.md                 # This file
```

## ğŸ”§ Hardware Requirements

- **GPU**: RTX 3050+ (4GB VRAM recommended)
- **CPU**: Multi-core processor
- **RAM**: 8GB+ recommended
- **Storage**: 2GB+ for models and embeddings

## ğŸš€ Features

### âœ… Production Ready
- **CLI-only operation** - Streamlined interface
- **Enhanced LLM responses** - Professional post-processing
- **Citation tracking** - Page-level source attribution
- **Enterprise-ready** - Production deployment ready
- **Performance optimized** - Clean, streamlined codebase

### ğŸ”„ Current Development
- Improving report detail and comprehensiveness
- Enhanced quantitative analysis extraction
- Multi-perspective analysis framework

## ğŸ“„ License

MIT License

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request